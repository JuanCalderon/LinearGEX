{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jU6Lu193FeL"
   },
   "source": [
    "# XAI Fidelity Benchmark Notebook\n",
    "\n",
    "It evaluates fidelity, runtime, and scalability of mainstream post-hoc explainers (**SHAP**, **LIME**) and our proposed pre-hoc approach (**LinearGEX**) across multiple short-text datasets (*MeOffendEs*, *HOPE*, *CheckWorthy*, *DANA*).\n",
    "\n",
    "The notebook contains the experiments reported in **Section 4** of the manuscript, computing fidelity as $R^2$ against each model’s native output (decision margins for LinearSVC, logits for BERT, and local surrogate fit for LIME). Auxiliary metrics (MAE or STD) and efficiency measures (per-instance time, batch size, batch runtime) are also recorded. Results are exported in structured tables consistent with the quantitative benchmarks presented in **Table 5** of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onU0MusD8VNI"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7730,
     "status": "ok",
     "timestamp": 1756244456895,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "UGknhJsx8mIF",
    "outputId": "885b39c2-e1bc-4c6d-9e91-3375530e712c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting microtc\n",
      "  Downloading microtc-2.4.13-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading microtc-2.4.13-py3-none-any.whl (83 kB)\n",
      "\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/83.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m83.2/83.2 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: microtc\n",
      "Successfully installed microtc-2.4.13\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/INGEOTEC/microtc\n",
    "try:\n",
    "    import microtc\n",
    "except ImportError:\n",
    "    !pip install microtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7025,
     "status": "ok",
     "timestamp": 1756244463931,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "BMhfZNZQPnvx",
    "outputId": "ef16f99e-4afa-4945-8e3f-4b516667ccc0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/275.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m275.7/275.7 kB\u001B[0m \u001B[31m20.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
      "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=9e67a15640943dc54022bc0fa1b3478bbbbf0c1cc61cc08fb398c51a192ea32b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
      "Successfully built lime\n",
      "Installing collected packages: lime\n",
      "Successfully installed lime-0.2.0.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import lime\n",
    "except ImportError:\n",
    "    !pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDTLWogH-e9q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from microtc import TextModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import time\n",
    "import shap\n",
    "import numpy as np\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import time\n",
    "from scipy.special import softmax\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20531,
     "status": "ok",
     "timestamp": 1756244507222,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "CcNPBPYc8mFB",
    "outputId": "a4d82202-a0e5-484b-c63a-a020be1cab06"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJGOmB2F8-FQ"
   },
   "outputs": [],
   "source": [
    "# Configuración\n",
    "base_ds_path = '/content/drive/MyDrive/Colab Notebooks/LinearGEX/ds/'\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Experimentos\n",
    "# =========================\n",
    "datasets = {\n",
    "    \"meoffendes\": {\n",
    "        \"train\": \"meoffendes_21_es_2_train.json\",\n",
    "        \"test\": \"meoffendes_21_es_2_test.json\",\n",
    "        \"bert_model\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "        \"num_labels\": 2,\n",
    "    },\n",
    "    \"hope\": {\n",
    "        \"train\": \"hope_24_en_4_train.json\",\n",
    "        \"test\": \"hope_24_en_4_test.json\",\n",
    "        \"bert_model\": \"bert-base-uncased\",\n",
    "        \"num_labels\": 4,\n",
    "    },\n",
    "    \"checkworthy\": {\n",
    "        \"train\": \"checkworthy_24_de_2_train.json\",\n",
    "        \"test\": \"checkworthy_24_de_2_test.json\",\n",
    "        \"bert_model\": \"bert-base-german-dbmdz-uncased\",\n",
    "        \"num_labels\": 2,\n",
    "    },\n",
    "    \"dana\": {\n",
    "        \"train\": \"dana_25_es_2_train.json\",\n",
    "        \"test\": \"dana_25_es_2_test.json\",\n",
    "        \"bert_model\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "        \"num_labels\": 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1756244699546,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "E0E8L9tCwYaY",
    "outputId": "9c17448c-c0c8-45e3-dd17-02adefdaca0d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Dataset: meoffendes ===\n",
      "                                                text  klass\n",
      "0  @USUARIO @USUARIO Que rico mamas el camote tie...      0\n",
      "1  Ampliación: La salida a final de mes del juego...      0\n",
      "Train: (3795, 2)\n",
      "Test: (1265, 2)\n",
      "\n",
      "=== Dataset: hope ===\n",
      "                                                text  klass\n",
      "0  Glad I didn't put this bullshit in my body. \\n...      0\n",
      "1  #USER# I was at this game. We lost, and I got ...      0\n",
      "Train: (4953, 2)\n",
      "Test: (1239, 2)\n",
      "\n",
      "=== Dataset: checkworthy ===\n",
      "                                                text  klass\n",
      "0  Die Ausbreitung des Virus sei beschränkter als...      0\n",
      "1    Zwar sei ein Anstieg der Zahlen zu verzeichnen.      0\n",
      "Train: (800, 2)\n",
      "Test: (224, 2)\n",
      "\n",
      "=== Dataset: dana ===\n",
      "                                                text  klass\n",
      "0   atentos a las palabras del coronel Baños. La ...      0\n",
      "1  @DavidRaventos68 Pots comprovar personalment c...      1\n",
      "Train: (520, 2)\n",
      "Test: (131, 2)\n",
      "/content/drive/MyDrive/Colab Notebooks/LinearGEX/ds/\n",
      "total 7651\n",
      "-rw------- 1 root root  157403 Aug 21 19:00 checkworthy_linearsvc_model.pkl\n",
      "-rw------- 1 root root  779237 Aug 21 19:00 checkworthy_tfidf_mtc.pkl\n",
      "-rw------- 1 root root  165003 Aug 21 19:00 dana_linearsvc_model.pkl\n",
      "-rw------- 1 root root  816641 Aug 21 19:00 dana_tfidf_mtc.pkl\n",
      "-rw------- 1 root root 1904963 Aug 21 19:00 hope_linearsvc_model.pkl\n",
      "-rw------- 1 root root 2410356 Aug 21 19:00 hope_tfidf_mtc.pkl\n",
      "-rw------- 1 root root  264539 Aug 21 19:00 meoffendes_linearsvc_model.pkl\n",
      "-rw------- 1 root root 1334540 Aug 21 19:00 meoffendes_tfidf_mtc.pkl\n"
     ]
    }
   ],
   "source": [
    "# Verificar Datasets y estructura de directorios\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(f\"\\n=== Dataset: {name} ===\")\n",
    "\n",
    "    train_path = f\"{base_ds_path}{info['train']}\"\n",
    "    test_path = f\"{base_ds_path}{info['test']}\"\n",
    "\n",
    "    X_train = pd.read_json(train_path, lines=True)#.sample(n=200, random_state=42)\n",
    "    X_test = pd.read_json(test_path, lines=True)#.sample(n=50, random_state=42)\n",
    "\n",
    "    print(X_train.head(2))\n",
    "\n",
    "    print(f\"Train: {X_train.shape}\")\n",
    "    print(f\"Test: {X_test.shape}\")\n",
    "\n",
    "#!ls -la '/content/drive/MyDrive/Colab Notebooks/LinearGEX/ds/'    ç\n",
    "base_ds_path = '/content/drive/MyDrive/Colab Notebooks/LinearGEX/ds/'\n",
    "print(base_ds_path)\n",
    "!ls -la \"{base_ds_path}/pretrained/linearsvc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuOkn3i1-OiL"
   },
   "outputs": [],
   "source": [
    "# =================\n",
    "# Función para cargar datasets\n",
    "\n",
    "def load_json_dataset(ds_info):\n",
    "    train_path = f\"{base_ds_path}{ds_info['train']}\"\n",
    "    test_path = f\"{base_ds_path}{ds_info['test']}\"\n",
    "\n",
    "    X_train = pd.read_json(train_path, lines=True)#.sample(n=200, random_state=42)\n",
    "    X_test = pd.read_json(test_path, lines=True)#.sample(n=50, random_state=42)\n",
    "\n",
    "    return X_train[\"text\"].astype(str).tolist(), X_train[\"klass\"].tolist(), X_test[\"text\"].astype(str).tolist(), X_test[\"klass\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iV7GL0NMr082"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Función auxiliar: métricas\n",
    "\n",
    "def compute_metrics(y_true, y_pred, average=\"macro\"):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=average, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=average, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=average, zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9XnUjPVfagi"
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dK0brWUVr1nl"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Entrenamiento LinearSVC\n",
    "\n",
    "def train_linearsvc(ds_name, ds_info):\n",
    "    # Cargar datos\n",
    "    X_train, y_train, X_test, y_test = load_json_dataset(ds_info)\n",
    "\n",
    "    # Vectorización TF-IDF (µTC con q-grams)\n",
    "    vectorizer = TextModel(token_list=[2, 3, 4], del_diac=True,  del_dup=False, lc=True, hashtag_option=None).fit(X_train)\n",
    "    # ToDo entreno con X_train, y vectorizo ambos con X_train. X_test podria tener tokens no considerados\n",
    "    X_train_vec, X_test_vec = vectorizer.transform(X_train), vectorizer.transform(X_test)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    clf = LinearSVC() # ToDo parametros del LinearSVC\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    metrics = compute_metrics(y_test, y_pred)\n",
    "\n",
    "    # Guardar modelo y vectorizador\n",
    "    joblib.dump(clf, f\"{base_ds_path}pretrained/linearsvc/{ds_name}_linearsvc_model.pkl\")\n",
    "    joblib.dump(vectorizer, f\"{base_ds_path}pretrained/linearsvc/{ds_name}_tfidf_mtc.pkl\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "recalculate = False"
   ],
   "metadata": {
    "id": "c6PJkCwTSt3T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29856,
     "status": "ok",
     "timestamp": 1755802843658,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "7KJ73sMewf8S",
    "outputId": "c6c4ee40-a677-4c00-d5c2-297b8cb85bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: meoffendes === {'train': 'meoffendes_21_es_2_train.json', 'test': 'meoffendes_21_es_2_test.json', 'bert_model': 'dccuchile/bert-base-spanish-wwm-cased', 'num_labels': 2}\n",
      "LinearSVC: {'accuracy': 0.783399209486166, 'precision': 0.7586934773909564, 'recall': 0.6919439792876569, 'f1': 0.7091963782318038}\n",
      "\n",
      "=== Dataset: hope === {'train': 'hope_24_en_4_train.json', 'test': 'hope_24_en_4_test.json', 'bert_model': 'bert-base-uncased', 'num_labels': 4}\n",
      "LinearSVC: {'accuracy': 0.6602098466505246, 'precision': 0.5765998537779892, 'recall': 0.5130118266612733, 'f1': 0.5323188848122438}\n",
      "\n",
      "=== Dataset: checkworthy === {'train': 'checkworthy_24_de_2_train.json', 'test': 'checkworthy_24_de_2_test.json', 'bert_model': 'bert-base-german-dbmdz-uncased', 'num_labels': 2}\n",
      "LinearSVC: {'accuracy': 0.7455357142857143, 'precision': 0.7049290372075182, 'recall': 0.6967228205836326, 'f1': 0.7003309315370714}\n",
      "\n",
      "=== Dataset: dana === {'train': 'dana_25_es_2_train.json', 'test': 'dana_25_es_2_test.json', 'bert_model': 'dccuchile/bert-base-spanish-wwm-cased', 'num_labels': 2}\n",
      "LinearSVC: {'accuracy': 0.8396946564885496, 'precision': 0.8412809724170174, 'recall': 0.8404850746268657, 'f1': 0.8396572827417381}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Loop LinearSVC\n",
    "# El modelo entrenado se guarda para reutilizarlo.\n",
    "\n",
    "if recalculate:\n",
    "\n",
    "    for ds_name, ds_info in datasets.items():\n",
    "        print(f\"\\n=== Dataset: {ds_name} === {ds_info}\")\n",
    "\n",
    "        metrics_svc = train_linearsvc(ds_name, ds_info)\n",
    "        print(\"LinearSVC:\", metrics_svc)\n",
    "\n",
    "        results.append((ds_name, \"LinearSVC\", metrics_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlCDwzquzBPi"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Entrenamiento BERT\n",
    "\n",
    "def train_bert(ds_name, ds_info):\n",
    "    # Cargar datos\n",
    "    X_train, y_train, X_test, y_test = load_json_dataset(ds_info)\n",
    "\n",
    "    # Crear datasets\n",
    "    train_ds = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "    test_ds = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "    # Tokenizador y modelo\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ds_info['bert_model'])\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    train_ds = train_ds.map(tokenize, batched=True)\n",
    "    test_ds = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(ds_info['bert_model'], num_labels=ds_info['num_labels'])\n",
    "\n",
    "    # Entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{base_ds_path}pretrained/bert/{ds_name}_bert\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "    )\n",
    "\n",
    "    def compute_metrics_trainer(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        return compute_metrics(labels, preds)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics_trainer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "\n",
    "    # Guardar modelo y tokenizador\n",
    "    model.save_pretrained(f\"{base_ds_path}pretrained/bert/{ds_name}_bert\")\n",
    "    tokenizer.save_pretrained(f\"{base_ds_path}pretrained/bert/{ds_name}_bert\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499,
     "referenced_widgets": [
      "716731dd84b54174b85141f1b7c7b840",
      "655e316584594404afcb250766e155c3",
      "39649be9e5e6450f9fe5312f46bed997",
      "00141fa283fe4518876fe5919fd65a69",
      "e573cdc4435e439d8264b75d41616a73",
      "b4430e9080464d868b1349705da1e5ff",
      "8e0e35987a524a2990ccfc60dd615a39",
      "67a51b4033cd4df0b1b7f966fddd89f8",
      "bbee3725c39a4beda7e6a9c824a3758a",
      "f2bb40469be543b282c880881ff21a0f",
      "5f38350565684996a8e3978b0f98ee5b",
      "dfdaeeebfdaa49298f038c4106aede95",
      "3c10462c3a874945a122164ad2dcd24e",
      "d15b4abff696475eb751088e7fa073aa",
      "8af756d4918b4c70877436e0e744990a",
      "8565b5a7f8c340218516431d7e6d4339",
      "6cffd44d23d34e8a984836d874188659",
      "b16b1b2b312547a3985c20d72a4fc5cc",
      "2ff29ebba5994b8bad0ded02c7ba489c",
      "8c99e6d62eb2497293fb64d1f66d7981",
      "3da5d699922c405f83a0bdf721444bd0",
      "50769cc07b714455970ee70ffb178104"
     ]
    },
    "executionInfo": {
     "elapsed": 171423,
     "status": "ok",
     "timestamp": 1755807238936,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "3Z-Ixuc6zsW3",
    "outputId": "478c1468-608f-4c34-ddad-b4230244d221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset: meoffendes === {'train': 'meoffendes_21_es_2_train.json', 'test': 'meoffendes_21_es_2_test.json', 'bert_model': 'dccuchile/bert-base-spanish-wwm-cased', 'num_labels': 2}\n",
      "\n",
      "=== Dataset: hope === {'train': 'hope_24_en_4_train.json', 'test': 'hope_24_en_4_test.json', 'bert_model': 'bert-base-uncased', 'num_labels': 4}\n",
      "\n",
      "=== Dataset: checkworthy === {'train': 'checkworthy_24_de_2_train.json', 'test': 'checkworthy_24_de_2_test.json', 'bert_model': 'bert-base-german-dbmdz-uncased', 'num_labels': 2}\n",
      "\n",
      "=== Dataset: dana === {'train': 'dana_25_es_2_train.json', 'test': 'dana_25_es_2_test.json', 'bert_model': 'dccuchile/bert-base-spanish-wwm-cased', 'num_labels': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716731dd84b54174b85141f1b7c7b840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdaeeebfdaa49298f038c4106aede95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-580855026.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [195/195 02:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.501350</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.774265</td>\n",
       "      <td>0.760961</td>\n",
       "      <td>0.759775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.542797</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.801423</td>\n",
       "      <td>0.801423</td>\n",
       "      <td>0.801423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.708264</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.781887</td>\n",
       "      <td>0.777285</td>\n",
       "      <td>0.777328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT: {'eval_loss': 0.5427970886230469, 'eval_accuracy': 0.8015267175572519, 'eval_precision': 0.8014225746268657, 'eval_recall': 0.8014225746268657, 'eval_f1': 0.8014225746268657, 'eval_runtime': 3.6367, 'eval_samples_per_second': 36.022, 'eval_steps_per_second': 4.675, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Loop LinearSVC\n",
    "\n",
    "if recalculate:\n",
    "    for ds_name, ds_info in datasets.items():\n",
    "        print(f\"\\n=== Dataset: {ds_name} === {ds_info}\")\n",
    "\n",
    "        if ds_name == \"dana\":\n",
    "            metrics_bert = train_bert(ds_name, ds_info)\n",
    "            print(\"BERT:\", metrics_bert)\n",
    "\n",
    "            results.append((ds_name, \"BERT\", metrics_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1755807455343,
     "user": {
      "displayName": "Juan Calderón",
      "userId": "17332892154385135452"
     },
     "user_tz": 360
    },
    "id": "jBOE-YdJzsRt",
    "outputId": "c10a0ebf-3913-407b-c616-e9c4a07650d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dataset     Modelo  Accuracy  Precision_macro  Recall_macro  F1_macro\n",
      "0   meoffendes  LinearSVC  0.783399         0.758693      0.691944  0.709196\n",
      "1         hope  LinearSVC  0.660210         0.576600      0.513012  0.532319\n",
      "2  checkworthy  LinearSVC  0.745536         0.704929      0.696723  0.700331\n",
      "3         dana  LinearSVC  0.839695         0.841281      0.840485  0.839657\n",
      "4   meoffendes       BERT  0.824506         0.795982      0.775867  0.784507\n",
      "5         hope       BERT  0.760291         0.682712      0.702993  0.691869\n",
      "6  checkworthy       BERT  0.857143         0.833893      0.838811  0.836257\n",
      "7         dana       BERT  0.801527         0.801423      0.801423  0.801423\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Mostrar resultados tabla\n",
    "\n",
    "rows = []\n",
    "for dataset, model, m in results:\n",
    "    accuracy = m['accuracy'] if 'accuracy' in m else m.get('eval_accuracy')\n",
    "    precision = m['precision'] if 'precision' in m else m.get('eval_precision')\n",
    "    recall = m['recall'] if 'recall' in m else m.get('eval_recall')\n",
    "    f1 = m['f1'] if 'f1' in m else m.get('eval_f1')\n",
    "    rows.append({\n",
    "        \"Dataset\": dataset,\n",
    "        \"Modelo\": model,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision_macro\": precision,\n",
    "        \"Recall_macro\": recall,\n",
    "        \"F1_macro\": f1,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "df.to_csv(f\"{base_ds_path}classification_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1_ePjY85vB3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ========================= Evaluación de explicabilidad ========================= #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOYqCQRvsHye"
   },
   "outputs": [],
   "source": [
    "# Reglas para batch size\n",
    "def batch_size_rules(inst_time):\n",
    "    # batch size adaptativo\n",
    "    if inst_time < 1.0:\n",
    "       batch_size = 1000\n",
    "    elif inst_time < 10.0:\n",
    "        batch_size = 100\n",
    "    elif inst_time < 60.0:\n",
    "        batch_size = 10\n",
    "    elif inst_time < 500.0:\n",
    "        batch_size = 5\n",
    "    else:\n",
    "        batch_size = None\n",
    "\n",
    "    print('Cero: ', inst_time, batch_size)\n",
    "\n",
    "    return batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ywLhlOTsoPu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7A0veQisoMy"
   },
   "outputs": [],
   "source": [
    "def run_xai_linearsvc(ds_name, X_test, y_test, base_ds_path):\n",
    "    \"\"\"\n",
    "      - SHAP.LinearExplainer: n_eval = full test; Fidelity=R2_margin, Aux=MAE_margin\n",
    "      - LIME: n_eval = 500 estratificado (seed=42); Fidelity=R2_local_mean, Aux=R2_local_std\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import joblib\n",
    "    import shap\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "    print(f\"\\n=== XAI (Linear) para {ds_name} ===\")\n",
    "\n",
    "    # Helpers\n",
    "\n",
    "    def _batch_size_rules_or_fallback(inst_time):\n",
    "        try:\n",
    "            # Use the global batch_size_rules function if it exists\n",
    "            bs = batch_size_rules(inst_time)\n",
    "            print(f\"[{ds_name}] batch_size_rules(inst_time={inst_time:.6f}) -> {bs}\")\n",
    "            return bs\n",
    "        except NameError:\n",
    "            # Fallback: same rules  (times in seconds)\n",
    "            if inst_time < 1:\n",
    "                bs = 1000\n",
    "            elif inst_time < 10:\n",
    "                bs = 100\n",
    "            elif inst_time < 60:\n",
    "                bs = 10\n",
    "            elif inst_time < 500:\n",
    "                bs = 5\n",
    "            else:\n",
    "                bs = None\n",
    "            print(f\"[{ds_name}] batch_size_rules (fallback) inst_time={inst_time:.6f} -> {bs}\")\n",
    "            return bs\n",
    "\n",
    "    def _sigmoid(z):\n",
    "        z = np.asarray(z, dtype=float)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def _softmax(z, axis=1):\n",
    "        z = np.asarray(z, dtype=float)\n",
    "        z = z - np.max(z, axis=axis, keepdims=True)\n",
    "        ez = np.exp(z)\n",
    "        # Avoid division by zero if sum is exactly 0.0\n",
    "        return ez / (np.sum(ez, axis=axis, keepdims=True) + 1e-12)\n",
    "\n",
    "    def make_predict_proba_fn(clf, vectorizer, n_classes):\n",
    "        \"\"\"Wrapper texto->proba: usa predict_proba si existe; si no, aproxima desde margin.\"\"\"\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            print(f\"[{ds_name}] predict_proba disponible en LinearSVC (calibrado).\")\n",
    "            def _pp(texts):\n",
    "                Xv = vectorizer.transform(texts)\n",
    "                return clf.predict_proba(Xv)\n",
    "            return _pp\n",
    "        else:\n",
    "            print(f\"[{ds_name}] predict_proba NO disponible; se aproximan proba desde decision_function.\")\n",
    "            def _pp(texts):\n",
    "                Xv = vectorizer.transform(texts)\n",
    "                margins = clf.decision_function(Xv)\n",
    "                if n_classes == 2:\n",
    "                    # Ensure margins is 1D for sigmoid in binary case\n",
    "                    if np.ndim(margins) == 2 and margins.shape[1] == 1:\n",
    "                        margins = margins.ravel()\n",
    "                    p1 = _sigmoid(margins)\n",
    "                    return np.vstack([1 - p1, p1]).T\n",
    "                else:\n",
    "                    return _softmax(margins, axis=1)\n",
    "            return _pp\n",
    "\n",
    "    def _normalize_shap_multiclase(shap_values, expected_value, n_classes):\n",
    "        \"\"\"\n",
    "        Devuelve (sv_list, ev_list):\n",
    "          - sv_list: lista de longitud C, cada elemento es (n_eval, n_features) para esa clase\n",
    "          - ev_list: lista de longitud C con expected_value (float) por clase\n",
    "        Acepta:\n",
    "          * shap_values: list[ndarray] por clase  O  ndarray 3D con ejes (n,p,C) o (C,n,p)\n",
    "          * expected_value: lista/ndarray por clase o escalar\n",
    "        \"\"\"\n",
    "        print(f\"[{ds_name}] Normalizando SHAP multiclase...\")\n",
    "        # SHAP values -> lista por clase\n",
    "        if isinstance(shap_values, list):\n",
    "            sv_list = shap_values\n",
    "            print(f\"[{ds_name}] shap_values es list con {len(sv_list)} clases.\")\n",
    "        else:\n",
    "            sv = np.asarray(shap_values)\n",
    "            print(f\"[{ds_name}] shap_values array con shape={sv.shape}\")\n",
    "            if sv.ndim != 3:\n",
    "                raise ValueError(f\"Forma SHAP inesperada (ndim={sv.ndim}). Esperado 3D o lista.\")\n",
    "            # Casos: (n, p, C) o (C, n, p)\n",
    "            if sv.shape[2] == n_classes:           # (n, p, C)\n",
    "                sv_list = [sv[:, :, c] for c in range(n_classes)]\n",
    "                print(f\"[{ds_name}] Interpretado como (n, p, C).\")\n",
    "            elif sv.shape[0] == n_classes:         # (C, n, p)\n",
    "                sv_list = [sv[c, :, :] for c in range(n_classes)]\n",
    "                print(f\"[{ds_name}] Interpretado como (C, n, p).\")\n",
    "            else:\n",
    "                raise ValueError(f\"Forma SHAP inesperada {sv.shape}. No coincide con n_clases={n_classes}.\")\n",
    "\n",
    "        # expected_value -> lista por clase\n",
    "        if isinstance(expected_value, (list, tuple, np.ndarray)):\n",
    "            ev_arr = np.atleast_1d(expected_value).astype(float)\n",
    "            if ev_arr.shape[0] == n_classes:\n",
    "                ev_list = [float(ev_arr[c]) for c in range(n_classes)]\n",
    "                print(f\"[{ds_name}] expected_value vector por clase con {n_classes} elementos.\")\n",
    "            else:\n",
    "                # Fallback: if it's an array/list but size doesn't match n_classes,\n",
    "                # assume it's a single value or needs to be broadcasted.\n",
    "                ev_list = [float(ev_arr.squeeze())] * n_classes\n",
    "                print(f\"[{ds_name}] expected_value escalar replicado a {n_classes}.\")\n",
    "        else:\n",
    "            # Scalar expected_value\n",
    "            ev_list = [float(expected_value)] * n_classes\n",
    "            print(f\"[{ds_name}] expected_value escalar replicado a {n_classes}.\")\n",
    "\n",
    "        return sv_list, ev_list\n",
    "\n",
    "    # --- helper para muestreo estratificado con semilla fija (mínimo cambio) ---\n",
    "    def _stratified_indices(y, n, seed=42):\n",
    "        y = np.asarray(y)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx_per_class = {c: np.where(y == c)[0].tolist() for c in np.unique(y)}\n",
    "        for lst in idx_per_class.values():\n",
    "            rng.shuffle(lst)\n",
    "        # cupos proporcionales (al menos 1 si hay muestras)\n",
    "        total = len(y)\n",
    "        alloc = {c: max(1, int(round(n * len(idx_per_class[c]) / total))) for c in np.unique(y)}\n",
    "        # ajustar por exceso/defecto\n",
    "        diff = n - sum(alloc.values())\n",
    "        # distribuir el diff\n",
    "        classes = list(idx_per_class.keys())\n",
    "        i = 0\n",
    "        while diff != 0 and len(classes) > 0:\n",
    "            c = classes[i % len(classes)]\n",
    "            if diff > 0 and alloc[c] < len(idx_per_class[c]):\n",
    "                alloc[c] += 1; diff -= 1\n",
    "            elif diff < 0 and alloc[c] > 1:\n",
    "                alloc[c] -= 1; diff += 1\n",
    "            i += 1\n",
    "        # construir índices\n",
    "        out = []\n",
    "        for c, k in alloc.items():\n",
    "            out.extend(idx_per_class[c][:k])\n",
    "        rng.shuffle(out)\n",
    "        return out[:n]\n",
    "\n",
    "\n",
    "    def measure_time_linear_shap(explainer, instance_vectorized, batch_data_vectorized):\n",
    "        import time\n",
    "        start = time.perf_counter()\n",
    "        # Ensure instance_vectorized is treated as a single instance (e.g., by wrapping in a list/array if needed)\n",
    "        # Assuming X_test_vec[0] is already a suitable representation for a single instance\n",
    "        _ = explainer.shap_values(instance_vectorized)\n",
    "        inst_time = (time.perf_counter() - start)\n",
    "        batch_size = _batch_size_rules_or_fallback(inst_time)\n",
    "        batch_time = None\n",
    "        if batch_size:\n",
    "            start = time.perf_counter()\n",
    "            _ = explainer.shap_values(batch_data_vectorized[:batch_size])\n",
    "            batch_time = time.perf_counter() - start\n",
    "        print(f\"[{ds_name}] SHAP timing -> inst={inst_time:.6f}s, batch_size={batch_size}, batch_time={batch_time}\")\n",
    "        return inst_time, batch_time, batch_size\n",
    "\n",
    "    def measure_time_linear_lime(lime_explainer, predict_fn, texts, num_features=10):\n",
    "        import time\n",
    "        if not texts:\n",
    "            print(f\"[{ds_name}] LIME timing -> No texts to measure.\")\n",
    "            return None, None, None # Or some default indicating no data\n",
    "\n",
    "        sample_text = texts[0]\n",
    "        start = time.perf_counter()\n",
    "        # explain_instance works on a single string, so texts[0] is correct\n",
    "        _ = lime_explainer.explain_instance(sample_text, predict_fn, num_features=num_features)\n",
    "        inst_time = (time.perf_counter() - start)\n",
    "        batch_size = _batch_size_rules_or_fallback(inst_time)\n",
    "        batch_time = None\n",
    "        if batch_size:\n",
    "            start = time.perf_counter()\n",
    "            # Explain each instance in the batch\n",
    "            for t in texts[:batch_size]:\n",
    "                _ = lime_explainer.explain_instance(t, predict_fn, num_features=num_features)\n",
    "            batch_time = time.perf_counter() - start\n",
    "        print(f\"[{ds_name}] LIME timing -> inst={inst_time:.6f}s, batch_size={batch_size}, batch_time={batch_time}\")\n",
    "        return inst_time, batch_time, batch_size\n",
    "\n",
    "    # Cargar modelo y vectorizador\n",
    "\n",
    "    print(f\"[{ds_name}] Cargando modelo y vectorizador...\")\n",
    "    clf = joblib.load(f\"{base_ds_path}pretrained/linearsvc/{ds_name}_linearsvc_model.pkl\")\n",
    "    vectorizer = joblib.load(f\"{base_ds_path}pretrained/linearsvc/{ds_name}_tfidf_mtc.pkl\")\n",
    "    print(f\"[{ds_name}] Modelo: {type(clf).__name__} | Vectorizer: {type(vectorizer).__name__}\")\n",
    "\n",
    "    texts_test = list(X_test) if not isinstance(X_test, list) else X_test\n",
    "    print(f\"[{ds_name}] #texts_test={len(texts_test)}\")\n",
    "\n",
    "    print(f\"[{ds_name}] #texts_test={len(texts_test)}\")\n",
    "    X_test_vec = vectorizer.transform(texts_test)\n",
    "    # Use sorted(np.unique(y_test)) to handle potential missing labels in test set\n",
    "    n_classes = len(np.unique(y_test))\n",
    "    print(f\"[{ds_name}] n_clases={n_classes} | X_test_vec shape={getattr(X_test_vec, 'shape', None)}\")\n",
    "\n",
    "    # 1) SHAP.LinearExplainer (fidelidad en margen, n_eval = full test)\n",
    "\n",
    "    print(f\"[{ds_name}] Preparando SHAP.LinearExplainer (espacio: margen)...\")\n",
    "    # Use a small, representative background dataset\n",
    "    bg_n = min(200, X_test_vec.shape[0])\n",
    "    bg_X = X_test_vec[:bg_n]\n",
    "    print(f\"[{ds_name}] Background size={bg_n}\")\n",
    "    # Initialize SHAP LinearExplainer with the model and background data\n",
    "    shap_explainer = shap.LinearExplainer(clf, bg_X)\n",
    "\n",
    "    # Measure timing\n",
    "    # Ensure X_test_vec[0] is a valid single instance representation\n",
    "    shap_inst_time, shap_batch_time, shap_batch_size = measure_time_linear_shap(\n",
    "        shap_explainer, X_test_vec[0], X_test_vec\n",
    "    )\n",
    "\n",
    "    # Fidelity evaluation (n_eval = ALL TEST DATA or batch_size if less)\n",
    "    # Adjusted n_eval to use the calculated batch_size, ensuring it's not larger than the test set\n",
    "    shap_n_eval = min(X_test_vec.shape[0], shap_batch_size if shap_batch_size is not None else X_test_vec.shape[0])\n",
    "    print(f\"[{ds_name}] SHAP n_eval (fidelidad)={shap_n_eval}\")\n",
    "    X_eval_shap = X_test_vec[:shap_n_eval]  # Evaluate on the first n_eval instances\n",
    "\n",
    "    print(f\"[{ds_name}] Calculando margins y SHAP values...\")\n",
    "    # Get decision function values (margins) from the model\n",
    "    margins = clf.decision_function(X_eval_shap)\n",
    "    # Get SHAP values for the evaluation data\n",
    "    shap_vals = shap_explainer.shap_values(X_eval_shap)\n",
    "    # Get the expected value (base value) from the explainer\n",
    "    phi0 = shap_explainer.expected_value\n",
    "    print(f\"[{ds_name}] margins shape={np.shape(margins)} | type(shap_vals)={type(shap_vals)} | phi0 type={type(phi0)}\")\n",
    "\n",
    "    errors = []\n",
    "    r2_margin = None # Initialize R2 margin\n",
    "\n",
    "    # Calculate fidelity based on whether it's binary or multiclass\n",
    "    if np.ndim(margins) == 1:\n",
    "        # --- Binary Case ---\n",
    "        print(f\"[{ds_name}] SHAP binario: usando clase positiva.\")\n",
    "        # SHAP values might be a list for binary, take the positive class (usually index 1)\n",
    "        if isinstance(shap_vals, list):\n",
    "            vals = shap_vals[1]\n",
    "        else:\n",
    "            vals = shap_vals # Should be (n_eval, n_features)\n",
    "\n",
    "        # Handle phi0 which might be a scalar or a list for binary\n",
    "        phi0_arr = np.atleast_1d(phi0).astype(float)\n",
    "        phi0_scalar = float(phi0_arr[1] if phi0_arr.size > 1 else phi0_arr.squeeze())\n",
    "\n",
    "        # Reconstruct the margin using SHAP values and the expected value\n",
    "        recon = np.sum(vals, axis=1) + phi0_scalar\n",
    "        # Calculate absolute error between reconstructed margin and actual margin\n",
    "        err = np.abs(recon - margins.astype(float))\n",
    "        errors = err\n",
    "\n",
    "        # Calculate R² margin for binary case\n",
    "        try:\n",
    "            ss_res = np.sum((margins - recon)**2)\n",
    "            ss_tot = np.sum((margins - np.mean(margins))**2) + 1e-12\n",
    "            r2_margin = float(1.0 - ss_res/ss_tot)\n",
    "        except Exception as e:\n",
    "            print(f\"[{ds_name}] R2 margen no calculado: {e}\")\n",
    "            r2_margin = None\n",
    "\n",
    "    else:\n",
    "        # --- Multiclass (OVR) Case ---\n",
    "        print(f\"[{ds_name}] SHAP multiclase: normalizando salida...\")\n",
    "        # Normalize SHAP values and expected values for multiclass\n",
    "        sv_list, ev_list = _normalize_shap_multiclase(shap_vals, phi0, n_classes)\n",
    "        # Find the top class for each instance based on the model's decision function\n",
    "        top_c = np.argmax(margins, axis=1)\n",
    "        errs = []\n",
    "        # Calculate error for the top class of each instance\n",
    "        for i in range(shap_n_eval):\n",
    "            c = int(top_c[i])  # The class being evaluated\n",
    "            vals_ic = sv_list[c][i]  # SHAP contributions for class c for instance i (n_features,)\n",
    "            phi0_c = ev_list[c]      # Expected value for class c (float)\n",
    "            recon_i = float(np.sum(vals_ic) + phi0_c)\n",
    "            errs.append(abs(recon_i - float(margins[i, c])))\n",
    "        errors = np.array(errs, dtype=float)\n",
    "\n",
    "    # Calculate MAE and Std Dev of errors\n",
    "    mae_margin = float(np.mean(errors))\n",
    "    err_std = float(np.std(errors))\n",
    "    print(f\"[{ds_name}] SHAP fidelidad -> MAE_margin={mae_margin:.6f}, err_std={err_std:.6f}, R2_margin={r2_margin}\")\n",
    "\n",
    "    # Store SHAP results in a dictionary (row for the results table)\n",
    "    row_shap = {\n",
    "        \"Dataset\": ds_name,\n",
    "        \"Model\": \"LinearSVC\",\n",
    "        \"Explainer\": \"SHAP.LinearExplainer\",\n",
    "        \"Time_inst\": float(shap_inst_time),\n",
    "        \"Time_batch\": float(shap_batch_time) if shap_batch_time is not None else None,\n",
    "        \"Batch_size\": int(shap_batch_size) if shap_batch_size is not None else None,\n",
    "        # Fidelity metrics: MAE as primary, R2 as auxiliary\n",
    "        \"Fidelity\": mae_margin,\n",
    "        \"Fidelity_metric\": \"MAE_margin\",\n",
    "        \"Fidelity_aux\": r2_margin # R2_margin is None for multiclass currently\n",
    "    }\n",
    "\n",
    "    # 2) LIME (R^2 local del surrogate) n_eval=500 estratificado\n",
    "    print(f\"[{ds_name}] Preparando LIME (R^2 local del surrogate)...\")\n",
    "    # Get class names for LIME (sorted unique labels)\n",
    "    class_names = [str(c) for c in sorted(np.unique(y_test))]\n",
    "    # Initialize LimeTextExplainer\n",
    "    lime_explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "    # Create a predict_proba function wrapper for LIME\n",
    "    predict_proba_fn = make_predict_proba_fn(clf, vectorizer, n_classes)\n",
    "\n",
    "    # Measure timing for LIME\n",
    "    # Pass the full list of texts for batch timing calculation\n",
    "    lime_inst_time, lime_batch_time, lime_batch_size = measure_time_linear_lime(\n",
    "        lime_explainer, predict_proba_fn, texts_test, num_features=10\n",
    "    )\n",
    "\n",
    "    # Fidelity evaluation (n_eval = 500 stratified or batch_size, whichever is smaller, but not more than test set)\n",
    "    # Using _stratified_indices for a fixed number (500) for consistency, but respecting test set size and batch size\n",
    "    lime_n_eval_target = 500 # Target number of evaluations for fidelity\n",
    "    # Determine actual n_eval based on test set size and batch size\n",
    "    lime_n_eval = min(len(texts_test), lime_batch_size if lime_batch_size is not None else lime_n_eval_target)\n",
    "    # If the test set or batch size is smaller than the target, use all available instances up to that limit\n",
    "    lime_n_eval = min(len(texts_test), lime_n_eval)\n",
    "\n",
    "    # Get stratified indices for the evaluation set (up to lime_n_eval)\n",
    "    # Ensure y_test has enough samples for stratification or handle smaller sets\n",
    "    if len(y_test) >= lime_n_eval and len(np.unique(y_test)) > 1: # Only stratify if possible\n",
    "       idx_eval = _stratified_indices(y_test, lime_n_eval, seed=42)\n",
    "    else:\n",
    "       idx_eval = list(range(lime_n_eval)) # Fallback to simple slicing\n",
    "\n",
    "    texts_eval = [texts_test[i] for i in idx_eval]\n",
    "    print(f\"[{ds_name}] LIME n_eval (fidelidad)={len(texts_eval)}\") # Use actual number of evaluated texts\n",
    "\n",
    "    r2_scores = []\n",
    "    # Explain each instance in the evaluation set and collect R2 scores\n",
    "    for idx, txt in enumerate(texts_eval, start=1):\n",
    "        # explain_instance calculates the local linear model and returns its score (R2)\n",
    "        exp = lime_explainer.explain_instance(txt, predict_proba_fn, num_features=10)\n",
    "        # Get the R2 score from the explanation object\n",
    "        r2 = getattr(exp, \"score\", None)\n",
    "        if r2 is None:\n",
    "            # This indicates LIME was not configured to return the R2 score\n",
    "            raise ValueError(\"LIME Explanation object does not have a 'score' attribute. Ensure LIME is configured to return R².\")\n",
    "        r2_scores.append(r2)\n",
    "        # Print progress periodically\n",
    "        if idx % max(1, len(texts_eval) // 5) == 0:\n",
    "            print(f\"[{ds_name}] LIME progreso {idx}/{len(texts_eval)} (R2 parcial mean={np.nanmean(r2_scores):.4f})\")\n",
    "\n",
    "    # Calculate mean and standard deviation of R2 scores\n",
    "    r2_scores = np.array(r2_scores, dtype=float)\n",
    "    r2_mean = float(np.nanmean(r2_scores))\n",
    "    r2_std = float(np.nanstd(r2_scores))\n",
    "    print(f\"[{ds_name}] LIME fidelidad -> R2_local_mean={r2_mean:.6f}, R2_local_std={r2_std:.6f}\")\n",
    "\n",
    "    # Store LIME results in a dictionary (row for the results table)\n",
    "    row_lime = {\n",
    "        \"Dataset\": ds_name,\n",
    "        \"Model\": \"LinearSVC\",\n",
    "        \"Explainer\": \"LimeTextExplainer\",\n",
    "        \"Time_inst\": float(lime_inst_time) if lime_inst_time is not None else None,\n",
    "        \"Time_batch\": float(lime_batch_time) if lime_batch_time is not None else None,\n",
    "        \"Batch_size\": int(lime_batch_size) if lime_batch_size is not None else None,\n",
    "        # Fidelity metrics: R2 mean as primary, R2 std as auxiliary\n",
    "        \"Fidelity\": r2_mean,\n",
    "        \"Fidelity_metric\": \"R2_local\",\n",
    "        \"Fidelity_aux\": r2_std # Std dev of local R2 scores\n",
    "    }\n",
    "\n",
    "    print(f\"[{ds_name}] OK: filas listas (SHAP y LIME).\")\n",
    "    return [row_shap, row_lime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgw69sh_s4YC"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Correr para todos los datasets\n",
    "\n",
    "if xai_results is None:\n",
    "    xai_results = []\n",
    "\n",
    "if False:\n",
    "    for ds_name, ds_info in datasets.items():\n",
    "        print(f\"\\n=== XAI para {ds_name} ===\")\n",
    "        X_train, y_train, X_test, y_test = load_json_dataset(ds_info)\n",
    "\n",
    "        # LinearSVC\n",
    "        xai_results.extend(run_xai_linearsvc(ds_name, X_test, y_test, base_ds_path))\n",
    "\n",
    "    df_xai = pd.DataFrame(xai_results)\n",
    "    print(df_xai)\n",
    "    df_xai.to_csv(f\"{base_ds_path}xai_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLMbEcBSuj1d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEuSK2wDeFkt"
   },
   "outputs": [],
   "source": [
    "def run_xai_bert(ds_name, X_test, y_test, base_ds_path, max_length=256, inf_batch_size=32, shap_explain_bs=16):\n",
    "    \"\"\"\n",
    "      - SHAP (Partition, logits): n_eval = 100 estratificado (seed=42); Fidelity=R2_logit, Aux=MAE_logit\n",
    "      - LIME: n_eval = 200 estratificado (seed=42); Fidelity=R2_local_mean, Aux=R2_local_std\n",
    "    \"\"\"\n",
    "    import os, re, numpy as np, torch, shap, pandas as pd\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "    from time import perf_counter\n",
    "\n",
    "    print(f\"\\n=== XAI (BERT) para {ds_name} ===\")\n",
    "\n",
    "    def _batch_size_rules_or_fallback(inst_time):\n",
    "        try:\n",
    "            bs = batch_size_rules(inst_time)\n",
    "            print(f\"[{ds_name}] batch_size_rules(inst_time={inst_time:.6f}) -> {bs}\")\n",
    "            return bs\n",
    "        except NameError:\n",
    "            if inst_time < 1: bs = 1000\n",
    "            elif inst_time < 10: bs = 100\n",
    "            elif inst_time < 60: bs = 10\n",
    "            elif inst_time < 500: bs = 5\n",
    "            else: bs = None\n",
    "            print(f\"[{ds_name}] batch_size_rules (fallback) inst_time={inst_time:.6f} -> {bs}\")\n",
    "            return bs\n",
    "\n",
    "    def _to_str_list(X, batch_size=None):\n",
    "        try:\n",
    "            return to_str_list(X, batch_size=batch_size)\n",
    "        except NameError:\n",
    "            if isinstance(X, pd.Series):\n",
    "                lst = X.astype(str).tolist()\n",
    "            elif isinstance(X, np.ndarray):\n",
    "                lst = X.astype(str).tolist()\n",
    "            elif isinstance(X, list):\n",
    "                lst = [str(x) for x in X]\n",
    "            else:\n",
    "                lst = [str(X)]\n",
    "            if batch_size is not None:\n",
    "                lst = lst[:batch_size]\n",
    "            return lst\n",
    "\n",
    "    def _softmax(z, axis=-1):\n",
    "        z = np.asarray(z, dtype=float)\n",
    "        if z.size == 0:\n",
    "            return z\n",
    "        z = z - np.max(z, axis=axis, keepdims=True)\n",
    "        ez = np.exp(z)\n",
    "        den = np.sum(ez, axis=axis, keepdims=True)\n",
    "        den[den == 0.0] = 1e-12\n",
    "        return ez / den\n",
    "\n",
    "    # --- Sanitización: garantizar ≥2 tokens por texto ---\n",
    "    _TOKEN_PATTERN = r\"\\w+|[^\\w\\s]\"\n",
    "    _token_regex = re.compile(_TOKEN_PATTERN, re.UNICODE)\n",
    "\n",
    "    def _ensure_min2_tokens_text(s: str) -> str:\n",
    "        s = \"\" if s is None else str(s)\n",
    "        toks = _token_regex.findall(s)\n",
    "        if len(toks) == 0:\n",
    "            return \"[UNK] [PAD]\"\n",
    "        if len(toks) == 1:\n",
    "            return s + \" [PAD]\"\n",
    "        return s\n",
    "\n",
    "    # --- helper estratificado (seed fija) ---\n",
    "    def _stratified_indices(y, n, seed=42):\n",
    "        y = np.asarray(y)\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx_per_class = {c: np.where(y == c)[0].tolist() for c in np.unique(y)}\n",
    "        for lst in idx_per_class.values(): rng.shuffle(lst)\n",
    "        total = len(y)\n",
    "        alloc = {c: max(1, int(round(n * len(idx_per_class[c]) / total))) for c in idx_per_class}\n",
    "        diff = n - sum(alloc.values())\n",
    "        classes = list(idx_per_class.keys()); i = 0\n",
    "        while diff != 0 and len(classes) > 0:\n",
    "            c = classes[i % len(classes)]\n",
    "            if diff > 0 and alloc[c] < len(idx_per_class[c]): alloc[c] += 1; diff -= 1\n",
    "            elif diff < 0 and alloc[c] > 1: alloc[c] -= 1; diff += 1\n",
    "            i += 1\n",
    "        out = []\n",
    "        for c, k in alloc.items(): out.extend(idx_per_class[c][:k])\n",
    "        rng.shuffle(out)\n",
    "        return out[:n]\n",
    "\n",
    "    # ---------- Carga modelo/tokenizer ----------\n",
    "    candidate_paths = [\n",
    "        f\"{base_ds_path}pretrained/bert/{ds_name}\",\n",
    "        f\"{base_ds_path}pretrained/bert/{ds_name}_bert\",\n",
    "        f\"{base_ds_path}pretrained/bert/{ds_name}_model\",\n",
    "    ]\n",
    "    model_dir = next((p for p in candidate_paths if os.path.isdir(p)), None)\n",
    "    if model_dir is None:\n",
    "        raise FileNotFoundError(f\"[{ds_name}] No se encontró directorio BERT. Probé: {candidate_paths}\")\n",
    "\n",
    "    print(f\"[{ds_name}] Cargando modelo/tokenizer desde: {model_dir}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "    n_classes = int(model.config.num_labels)\n",
    "    print(f\"[{ds_name}] num_labels={n_classes} | device={device} | max_length={max_length} | inf_batch_size={inf_batch_size}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_logits(texts):\n",
    "        texts = _to_str_list(texts)\n",
    "        if len(texts) == 0: return np.zeros((0, n_classes), dtype=float)\n",
    "        outs = []\n",
    "        for i in range(0, len(texts), inf_batch_size):\n",
    "            batch = texts[i:i+inf_batch_size]\n",
    "            enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length).to(device)\n",
    "            logits = model(**enc).logits.detach().cpu().numpy()\n",
    "            outs.append(logits)\n",
    "        return np.vstack(outs) if outs else np.zeros((0, n_classes), dtype=float)\n",
    "\n",
    "    def predict_proba(texts):\n",
    "        logits = predict_logits(texts)\n",
    "        return _softmax(logits, axis=1)\n",
    "\n",
    "    # Textos de test con ≥2 tokens garantizados\n",
    "    texts_test = _to_str_list(X_test)\n",
    "    texts_test = [_ensure_min2_tokens_text(t) for t in texts_test]\n",
    "    print(f\"[{ds_name}] #texts_test={len(texts_test)}\")\n",
    "\n",
    "    # ---------- SHAP (Partition, logits) ----------\n",
    "    print(f\"[{ds_name}] Preparando SHAP.PartitionExplainer (espacio: logits)...\")\n",
    "    masker = shap.maskers.Text(_TOKEN_PATTERN)  # tokeniza por regex (palabras y signos)\n",
    "    print(f\"[{ds_name}] masker=Text(regex={_TOKEN_PATTERN})\")\n",
    "    explainer_shap = shap.Explainer(predict_logits, masker, algorithm=\"partition\",\n",
    "                                    output_names=[str(i) for i in range(n_classes)])\n",
    "\n",
    "    # timings intactos\n",
    "    t0 = perf_counter(); _ = explainer_shap([texts_test[0]]); shap_inst_time = perf_counter() - t0\n",
    "    shap_batch_size = _batch_size_rules_or_fallback(shap_inst_time)\n",
    "    shap_batch_time = None\n",
    "    if shap_batch_size:\n",
    "        t0 = perf_counter(); _ = explainer_shap(texts_test[:shap_batch_size]); shap_batch_time = perf_counter() - t0\n",
    "    print(f\"[{ds_name}] SHAP timing -> inst={shap_inst_time:.6f}s, batch_size={shap_batch_size}, batch_time={shap_batch_time}\")\n",
    "\n",
    "    # n_eval fijo y estratificado\n",
    "    shap_n_eval = min(len(texts_test), 100)\n",
    "    idx_eval_shap = _stratified_indices(y_test, shap_n_eval, seed=42)\n",
    "    texts_eval = [texts_test[i] for i in idx_eval_shap]\n",
    "    print(f\"[{ds_name}] SHAP n_eval (fidelidad)={shap_n_eval} (estratificado, seed=42)\")\n",
    "\n",
    "    logits_true = predict_logits(texts_eval)\n",
    "    if logits_true.shape[0] == 0:\n",
    "        raise RuntimeError(f\"[{ds_name}] predict_logits devolvió (0, C) para textos no vacíos.\")\n",
    "    top_c = np.argmax(logits_true, axis=1)\n",
    "\n",
    "    # explicar por bloques con tolerancia\n",
    "    exps, ok_idx = [], []\n",
    "    for i in range(0, shap_n_eval, shap_explain_bs):\n",
    "        chunk_idx = list(range(i, min(i+shap_explain_bs, shap_n_eval)))\n",
    "        chunk_texts = [texts_eval[k] for k in chunk_idx]\n",
    "        try:\n",
    "            e_chunk = explainer_shap(chunk_texts)\n",
    "            exps.extend(list(e_chunk)); ok_idx.extend(chunk_idx)\n",
    "            print(f\"[{ds_name}] SHAP progreso {chunk_idx[-1]+1}/{shap_n_eval}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{ds_name}] SHAP batch fallo en [{i}:{i+shap_explain_bs}]: {e} -> instancia-por-instancia\")\n",
    "            for k in chunk_idx:\n",
    "                try:\n",
    "                    e1 = explainer_shap([texts_eval[k]])\n",
    "                    exps.extend(list(e1)); ok_idx.append(k)\n",
    "                except Exception as e2:\n",
    "                    print(f\"[{ds_name}] SHAP omitida inst {k}: {e2}\")\n",
    "\n",
    "    if len(ok_idx) == 0:\n",
    "        raise RuntimeError(f\"[{ds_name}] No se pudo generar ninguna explicación SHAP.\")\n",
    "\n",
    "    # Reconstrucción de logit para clase top\n",
    "    y_true, y_hat, abs_errors = [], [], []\n",
    "    for cnt, k in enumerate(ok_idx, start=1):\n",
    "        exp = exps[cnt-1]\n",
    "        vals = np.asarray(exp.values)\n",
    "        # Normalizar a (tokens, C)\n",
    "        if vals.ndim == 2 and vals.shape[1] == n_classes:\n",
    "            token_class = vals\n",
    "        elif vals.ndim == 2 and n_classes == 2 and vals.shape[1] == 1:\n",
    "            token_class = np.hstack([-vals, vals])  # (tokens, 2)\n",
    "        elif vals.ndim == 1 and n_classes == 2:\n",
    "            token_class = np.vstack([-vals, vals]).T\n",
    "        else:\n",
    "            raise ValueError(f\"[{ds_name}] SHAP: valores con forma {vals.shape}, inesperada para n_classes={n_classes}.\")\n",
    "\n",
    "        base_vals = np.asarray(exp.base_values)\n",
    "        if base_vals.ndim == 1 and base_vals.shape[0] == n_classes:\n",
    "            base = base_vals\n",
    "        else:\n",
    "            base = np.ravel(base_vals)\n",
    "            if base.shape[0] != n_classes:\n",
    "                base = np.full((n_classes,), float(base_vals if np.isscalar(base_vals) else np.mean(base_vals)))\n",
    "\n",
    "        c = int(top_c[k])\n",
    "        recon_c = float(token_class[:, c].sum() + float(base[c]))\n",
    "        y_hat.append(recon_c); y_true.append(float(logits_true[k, c]))\n",
    "        abs_errors.append(abs(recon_c - float(logits_true[k, c])))\n",
    "\n",
    "        if cnt % max(1, len(ok_idx)//5) == 0:\n",
    "            print(f\"[{ds_name}] SHAP recon progreso {cnt}/{len(ok_idx)} | err_abs_mean={np.mean(abs_errors):.4f}\")\n",
    "\n",
    "    y_true = np.array(y_true, dtype=float); y_hat = np.array(y_hat, dtype=float)\n",
    "    abs_errors = np.array(abs_errors, dtype=float)\n",
    "\n",
    "    mae_logit = float(np.mean(abs_errors))\n",
    "    try:\n",
    "        ss_res = np.sum((y_true - y_hat)**2); ss_tot = np.sum((y_true - np.mean(y_true))**2) + 1e-12\n",
    "        r2_logit = float(1.0 - ss_res/ss_tot)\n",
    "    except Exception as e:\n",
    "        print(f\"[{ds_name}] R2_logit no calculado: {e}\"); r2_logit = None\n",
    "\n",
    "    print(f\"[{ds_name}] SHAP fidelidad -> R2_logit={r2_logit}, MAE_logit={mae_logit:.6f}\")\n",
    "    row_shap = {\n",
    "        \"Dataset\": ds_name, \"Model\": \"BERT\", \"Explainer\": \"SHAP.PartitionExplainer\",\n",
    "        \"Time_inst\": float(shap_inst_time), \"Time_batch\": float(shap_batch_time) if shap_batch_time is not None else None,\n",
    "        \"Batch_size\": int(shap_batch_size) if shap_batch_size is not None else None,\n",
    "        \"Fidelity\": r2_logit, \"Fidelity_metric\": \"R2_logit\", \"Fidelity_aux\": mae_logit\n",
    "    }\n",
    "\n",
    "    # ---------- LIME (R2_local) ----------\n",
    "    print(f\"[{ds_name}] Preparando LIME (R2 local del surrogate)...\")\n",
    "    class_names = [str(c) for c in sorted(np.unique(y_test))]\n",
    "    lime_explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "    # timings intactos\n",
    "    t0 = perf_counter(); _ = lime_explainer.explain_instance(texts_test[0], predict_proba, num_features=10)\n",
    "    lime_inst_time = perf_counter() - t0\n",
    "    lime_batch_size = _batch_size_rules_or_fallback(lime_inst_time)\n",
    "    lime_batch_time = None\n",
    "    if lime_batch_size:\n",
    "        t0 = perf_counter()\n",
    "        for t in texts_test[:lime_batch_size]:\n",
    "            _ = lime_explainer.explain_instance(t, predict_proba, num_features=10)\n",
    "        lime_batch_time = perf_counter() - t0\n",
    "    print(f\"[{ds_name}] LIME timing -> inst={lime_inst_time:.6f}s, batch_size={lime_batch_size}, batch_time={lime_batch_time}\")\n",
    "\n",
    "    # n_eval fijo y estratificado\n",
    "    lime_n_eval = min(len(texts_test), 200)\n",
    "    idx_eval_lime = _stratified_indices(y_test, lime_n_eval, seed=42)\n",
    "    texts_eval = [texts_test[i] for i in idx_eval_lime]\n",
    "    print(f\"[{ds_name}] LIME n_eval (fidelidad)={lime_n_eval} (estratificado, seed=42)\")\n",
    "\n",
    "    r2_scores = []\n",
    "    for i, txt in enumerate(texts_eval, start=1):\n",
    "        exp = lime_explainer.explain_instance(txt, predict_proba, num_features=10)\n",
    "        r2 = getattr(exp, \"score\", None)\n",
    "        if r2 is None:\n",
    "            raise ValueError(\"LIME Explanation no tiene 'score'. Configura LIME para devolver R².\")\n",
    "        r2_scores.append(r2)\n",
    "        if i % max(1, lime_n_eval // 5) == 0:\n",
    "            print(f\"[{ds_name}] LIME progreso {i}/{lime_n_eval} (R2 parcial mean={np.nanmean(r2_scores):.4f})\")\n",
    "\n",
    "    r2_scores = np.array(r2_scores, dtype=float)\n",
    "    r2_mean = float(np.nanmean(r2_scores)); r2_std = float(np.nanstd(r2_scores))\n",
    "    print(f\"[{ds_name}] LIME fidelidad -> R2_local_mean={r2_mean:.6f}, R2_local_std={r2_std:.6f}\")\n",
    "    row_lime = {\n",
    "        \"Dataset\": ds_name, \"Model\": \"BERT\", \"Explainer\": \"LimeTextExplainer\",\n",
    "        \"Time_inst\": float(lime_inst_time), \"Time_batch\": float(lime_batch_time) if lime_batch_time is not None else None,\n",
    "        \"Batch_size\": int(lime_batch_size) if lime_batch_size is not None else None,\n",
    "        \"Fidelity\": r2_mean, \"Fidelity_metric\": \"R2_local\", \"Fidelity_aux\": r2_std\n",
    "    }\n",
    "\n",
    "    print(f\"[{ds_name}] OK: filas listas (SHAP y LIME).\")\n",
    "    return [row_shap, row_lime]\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================\n",
    "# Correr para todos los datasets\n",
    "\n",
    "xai_results = []\n",
    "if xai_results is None:\n",
    "    xai_results = []\n",
    "\n",
    "for ds_name, ds_info in datasets.items():\n",
    "    print(f\"\\n=== XAI para {ds_name} ===\")\n",
    "    X_train, y_train, X_test, y_test = load_json_dataset(ds_info)\n",
    "\n",
    "    # BERT (timings intactos; fidelidad estandarizada)\n",
    "    xai_results.extend(run_xai_bert(ds_name, X_test, y_test, base_ds_path))\n",
    "\n",
    "df_xai = pd.DataFrame(xai_results)\n",
    "print(df_xai)\n",
    "df_xai.to_csv(f\"{base_ds_path}xai_results_bert_solo_dana_today.csv\", index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jByLc_7Ozh8O"
   },
   "source": [
    "\n",
    "* LinearSVC+LIME → `Fidelity=R2_local_mean`, `Aux=R2_local_std`.\n",
    "* LinearSVC+SHAP → `Fidelity=R2_margin`, `Aux=MAE_margin`.\n",
    "* BERT+LIME → `Fidelity=R2_local_mean`, `Aux=R2_local_std`.\n",
    "* BERT+SHAP → `Fidelity=R2_logit`, `Aux=MAE_logit`.\n",
    "\n",
    ">\n",
    "\n",
    "* **LinearSVC + LIME (500)**: más estable y comparable; más coste en fidelidad por evaluar más instancias.\n",
    "* **LinearSVC + SHAP (todo test)**: máxima precisión (R²≈1, MAE≈0) con coste mínimo; mejora la solidez del reporte.\n",
    "* **BERT + LIME (200)**: R² local más estable que con 10/100 muestras; coste extra en fidelidad.\n",
    "* **BERT + SHAP (100)**: suficiente para un R²\\_logit representativo, con coste **menor** que antes si intentabas evaluar cientos/miles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdl8A9s_5u-v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "11Q1HetRtWUkdVeArvLDlMVXzCGUMMQ7R",
     "timestamp": 1756082620148
    },
    {
     "file_id": "1HhTOlsFcCqYPjsuoY85Ugpj4tFk3qtUX",
     "timestamp": 1756061521443
    }
   ],
   "authorship_tag": "ABX9TyMAFtuqwdzK45t8cvt5g7i2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
